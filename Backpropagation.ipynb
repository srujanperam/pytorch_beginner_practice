{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0EtmAVixZcQSiFAPluMcp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srujanperam/pytorch_beginner_practice/blob/main/Backpropagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7mSzHcoU9dNE"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(4.0, requires_grad=True)"
      ],
      "metadata": {
        "id": "zUz-WsMJBSje"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODvcTo-bCPAu",
        "outputId": "98695ffe-2b92-4d32-da81-b32903c52fee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4., requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x**2\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeTzLOFhCPJ7",
        "outputId": "c4e47553-914f-4575-ddac-ad7705868cdc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(16., grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()"
      ],
      "metadata": {
        "id": "iW3f4zHoCSTr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: what is y.backward() and why we need to call to get x.grad? what does this has to do with ANN\n",
        "\n",
        "x.grad"
      ],
      "metadata": {
        "id": "rPydWFVsDgBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad1d3749-7f8c-487b-8e39-337c57a1bd2d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8.)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Szro47wlCUVN",
        "outputId": "ac16efa5-a857-4618-bca2-4999cad7a899"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [[2.,3.,1.],[4.,5.,3.],[7.,6.,4.]]\n",
        "torch_input = torch.tensor(lst, requires_grad=True)"
      ],
      "metadata": {
        "id": "TP4SX0EAC7nP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbQ8id_yC_K7",
        "outputId": "2ecb4ab8-bb47-4f4a-d107-6597e2e12297"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 3., 1.],\n",
              "        [4., 5., 3.],\n",
              "        [7., 6., 4.]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch_input**3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpTabXoADOSJ",
        "outputId": "31ab8032-4a79-4b48-bcab-5bf7528e303c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  8.,  27.,   1.],\n",
              "        [ 64., 125.,  27.],\n",
              "        [343., 216.,  64.]], grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch_input**2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSMd7k6TDRFK",
        "outputId": "6711bd1e-d2c1-4dae-fed6-118db466b89b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4.,  9.,  1.],\n",
              "        [16., 25.,  9.],\n",
              "        [49., 36., 16.]], grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch_input**3 + torch_input**2"
      ],
      "metadata": {
        "id": "-RR6J4FmDDEU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eYz8-DLDS90",
        "outputId": "f2601bea-8190-41ec-ef59-b07b737028c1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 12.,  36.,   2.],\n",
              "        [ 80., 150.,  36.],\n",
              "        [392., 252.,  80.]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z= y.sum()\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEBG4YxhDTT_",
        "outputId": "3c529682-f1ee-4ffe-abb0-23cf685b6f69"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1040., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z.backward()"
      ],
      "metadata": {
        "id": "vdLlE8x-DYqM"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch_input.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK3CBQK4DdNz",
        "outputId": "9e9b30aa-41e5-4b0e-9fd0-83630634a339"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 16.,  33.,   5.],\n",
              "        [ 56.,  85.,  33.],\n",
              "        [161., 120.,  56.]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: explain torch_input.grad ouput with mathmatical\n",
        "\n",
        "Okay, let's break down the `torch_input.grad` output with mathematical explanation.\n",
        "\n",
        "**Background:**\n",
        "\n",
        "* **Computational Graph:** PyTorch automatically constructs a computational graph when you perform operations on tensors with `requires_grad=True`. This graph tracks the operations and allows for automatic differentiation.\n",
        "* **Backpropagation:** When you call `z.backward()`, PyTorch performs backpropagation through the computational graph. It calculates the gradients of `z` with respect to each tensor involved in the computation.\n",
        "* **Gradient:** The gradient represents the rate of change of a function with respect to its input variables. In this case, we are interested in the gradient of `z` with respect to `torch_input`.\n",
        "\n",
        "\n",
        "**Mathematical Explanation for `torch_input.grad`:**\n",
        "\n",
        "1. **`y = torch_input**3 + torch_input**2`:**  We have a function `y` defined as a sum of two terms: `torch_input**3` and `torch_input**2`.\n",
        "2. **`z = y.sum()`:** We are calculating the sum of all elements in `y`, which is our scalar output `z`.\n",
        "3. **Backpropagation (`z.backward()`):**  We want to compute the gradient of `z` with respect to each element in `torch_input`.\n",
        "\n",
        "**Let's focus on calculating the gradient of `z` with respect to a single element of `torch_input`, let's say `torch_input[i, j]`:**\n",
        "\n",
        "* **Chain Rule:** We'll use the chain rule to calculate this gradient. The chain rule states that if we have a function `z = f(y)` and `y = g(x)`, then the derivative of `z` with respect to `x` is `dz/dx = dz/dy * dy/dx`.\n",
        "* **Gradient of `z` with respect to `y[i, j]`:** Since `z` is the sum of all elements in `y`, the gradient of `z` with respect to `y[i, j]` is simply `dz/dy[i, j] = 1`.\n",
        "* **Gradient of `y[i, j]` with respect to `torch_input[i, j]`:**\n",
        "   * `y[i, j] = torch_input[i, j]**3 + torch_input[i, j]**2`.\n",
        "   * `dy[i, j]/d(torch_input[i, j]) = 3 * torch_input[i, j]**2 + 2 * torch_input[i, j]` (using the power rule of differentiation).\n",
        "* **Combining the chain rule:**\n",
        "   `dz/d(torch_input[i, j]) = dz/dy[i, j] * dy[i, j]/d(torch_input[i, j]) = 1 * (3 * torch_input[i, j]**2 + 2 * torch_input[i, j])`.\n",
        "\n",
        "\n",
        "**In essence, each element of `torch_input.grad` will contain the following value:**\n",
        "\n",
        "`3 * torch_input[i, j]**2 + 2 * torch_input[i, j]`\n",
        "\n",
        "\n",
        "**Example:** If `torch_input[0, 0]` is 2, then the corresponding element in `torch_input.grad` will be:\n",
        "`3 * 2**2 + 2 * 2 = 12 + 4 = 16`.\n",
        "\n",
        "\n",
        "**In Summary:** `torch_input.grad` provides the gradient of the scalar output `z` with respect to each element in `torch_input`. This gradient is calculated using the chain rule and is essential for updating the `torch_input` values during optimization (e.g., in gradient descent) to minimize the `z` value."
      ],
      "metadata": {
        "id": "gb07kRxT8_20"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}